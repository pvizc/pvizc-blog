<!DOCTYPE html>
<html lang="es"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
   <meta name="description" content="Hace unos días asistí a un coloquio sobre Inteligencia artificial y observé un patrón reconocible: el miedo ocupa más espacio que la comprensión. Cuatro ponentes (dos periodistas, una experta en propiedad intelectual y un catedrático especializado en procesamiento del lenguaje natural) ofrecieron una panorámica casi monocromática. El mensaje principal podía resumirse así: la IA representa una amenaza para la creatividad, para el pensamiento crítico y para la verdad.
Es comprensible que aparezcan estas preocupaciones. La inteligencia artificial ha irrumpido con una velocidad inusual en nuestra vida cotidiana. En pocos meses, ha pasado de ser una curiosidad técnica a una herramienta de trabajo real. Cuando un cambio tecnológico sucede tan deprisa, la reacción inicial suele ser defensiva. Sin embargo, cuando el miedo se convierte en el único marco de análisis, corremos el riesgo de perder lo más valioso que la curiosidad humana nos ofrece: la posibilidad de aprender.">  

  <title>
    
      Lo que se pierde cuando solo hablamos del miedo
    
  </title>


  <link rel="shortcut icon" type="image/x-icon" href="/" />
  
  
  
  <link rel="stylesheet" href="/css/main.900100e9dbee2d56c58fac8bb717037cae7e26a9c36c29d2ff587bdd65f0cbbe510b41d81a3bb234919cdfdc7550d786b2fab70c8fc507772d732fe097106d12.css" integrity="sha512-kAEA6dvuLVbFj6yLtxcDfK5&#43;JqnDbCnS/1h73WXwy75RC0HYGjuyNJGc39x1UNeGsvq3DI/FB3ctcy/glxBtEg==" />
  
</head>
<body a="auto">
        <main class="page-content" aria-label="Content">
            <div class="w">
                <div class="post-meta">
                    <a href="/">..</a>

                    <p>
                        <time datetime="2025-10-27 22:36:24 &#43;0100 CET">
                            2025-10-27
                        </time>
                    </p>
                </div>

<article>
    <h1>Lo que se pierde cuando solo hablamos del miedo</h1>

    

    <p>Hace unos días asistí a un coloquio sobre Inteligencia artificial y observé un patrón reconocible: el miedo ocupa más espacio que la comprensión. Cuatro ponentes (dos periodistas, una experta en propiedad intelectual y un catedrático especializado en procesamiento del lenguaje natural) ofrecieron una panorámica casi monocromática. El mensaje principal podía resumirse así: la IA representa una amenaza para la creatividad, para el pensamiento crítico y para la verdad.</p>
<p>Es comprensible que aparezcan estas preocupaciones. La inteligencia artificial ha irrumpido con una velocidad inusual en nuestra vida cotidiana. En pocos meses, ha pasado de ser una curiosidad técnica a una herramienta de trabajo real. Cuando un cambio tecnológico sucede tan deprisa, la reacción inicial suele ser defensiva. Sin embargo, cuando el miedo se convierte en el único marco de análisis, corremos el riesgo de perder lo más valioso que la curiosidad humana nos ofrece: la posibilidad de aprender.</p>
<p>Uno de los ponentes, el catedrático, relató un experimento interesante. Compararon los relatos de un escritor profesional con los generados por GPT-4, el modelo de lenguaje más avanzado de OpenAI. Los textos fueron evaluados a ciegas por un grupo de expertos, y el escritor humano ganó “por goleada”. La conclusión parecía clara: la máquina aún está lejos del talento humano.
Pero el propio investigador añadió un matiz que pasó casi desapercibido: cuando se pedía a la IA escribir con la premisa y el tono del autor, los resultados mejoraban drásticamente, hasta acercarse a su nivel. En otras palabras, el problema no estaba en la herramienta, sino en la dirección creativa. La calidad dependía del uso humano. Ese detalle, que es el más importante de todos, quedó relegado a una nota de color.</p>
<p>También se abordó el tema de la autoría. Uno de los participantes, el escritor Rubén Amón, contó que su editorial le había pedido firmar una cláusula declarando que no había utilizado inteligencia artificial en su próxima obra. Él mismo ironizó con la situación: sería como obligar a un autor a firmar que “no ha usado internet” para escribir. Y es cierto.
Hoy es casi imposible separar lo humano de lo tecnológico. Los procesadores de texto, los buscadores, los correctores o las bases de datos literarias incorporan modelos de IA de algún tipo. Prohibir su uso no es proteger la creatividad, sino negar la realidad de cómo creamos hoy. Lo razonable no sería exigir pureza, sino transparencia: reconocer el grado de intervención humana y valorar el criterio detrás de cada decisión.</p>
<p>Otro concepto que reapareció con insistencia fue el de las “alucinaciones”. Se dijo que ChatGPT o herramientas similares “inventan” hechos o datos. Es cierto: los modelos de lenguaje no tienen conciencia ni verificación interna, y pueden producir errores. Pero presentarlo como un defecto estructural, casi moral, es una simplificación.
Los modelos fallan cuando se les pide operar fuera de su contexto de precisión, igual que un humano puede equivocarse cuando improvisa sobre algo que desconoce. En realidad, lo que necesitamos no es demonizar el error, sino aprender a diseñar contextos de uso donde el error se detecte y se corrija.</p>
<p>Todo esto nos lleva a una paradoja curiosa: celebramos la inteligencia artificial cuando ayuda a detectar tumores o predecir patrones climáticos, pero la tememos cuando sugiere una frase bien escrita. En lo técnico, la aplaudimos; en lo simbólico, la rechazamos.
Quizá porque el arte y el lenguaje tocan la parte más íntima de nuestra identidad. Nos cuesta aceptar que una herramienta pueda participar en ese territorio. Pero la creatividad nunca ha sido un acto aislado. Siempre ha dependido de instrumentos: de la imprenta, del teclado, del procesador de texto. Lo nuevo no borra lo humano, lo amplifica.</p>
<p>Hablar de miedo es necesario; lo que no podemos hacer es quedarnos solo ahí. Si reducimos la conversación a los riesgos, perdemos claridad, oportunidad y honestidad.
Clareza, porque confundimos los límites técnicos con defectos morales.
Oportunidad, porque dejamos de explorar usos valiosos.
Y honestidad, porque nos escudamos en el miedo para no admitir que el cambio ya está ocurriendo.</p>
<p>El reto, en el fondo, no es decidir si la inteligencia artificial tiene derecho a existir, sino aprender a convivir con ella de forma crítica, ética y creativa.
Cuando solo hablamos del miedo, renunciamos a eso. Y con ello, perdemos algo más que control: perdemos la oportunidad de comprendernos mejor a nosotros mismos.</p>

</article>

            </div>
        </main>
    </body></html>
